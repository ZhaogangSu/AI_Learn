{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cae2d59",
   "metadata": {},
   "source": [
    "# Simple Language Model (Predict next char)\n",
    "## 1. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0114e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer import TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5d592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_heads, d_ff, n_layers, max_seq_len, droput=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(vocab_size, d_model, n_heads, d_ff, n_layers, max_seq_len, droput)\n",
    "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len) - token IDs\n",
    "        x = self.encoder(x) # (batch, seq_len, d_model)\n",
    "        logits = self.output_proj(x) # (batch, seq_len, vocab_size)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a5c56",
   "metadata": {},
   "source": [
    "## 2. Prepare simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49c8348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 40\n",
      "Characters: ['\\n', ' ', \"'\", ',', '-', '.', ':', ';', 'A', 'D', 'F', 'M', 'N', 'O', 'T', 'W', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y', '—']\n",
      "Text length: 604\n"
     ]
    }
   ],
   "source": [
    "# text = \"\"\"To be or not to be, that is the question.\n",
    "# Whether 'tis nobler in the mind to suffer\n",
    "# The slings and arrows of outrageous fortune,\n",
    "# Or to take arms against a sea of troubles.\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "To be, or not to be, that is the question:\n",
    "Whether 'tis nobler in the mind to suffer\n",
    "The slings and arrows of outrageous fortune,\n",
    "Or to take arms against a sea of troubles\n",
    "And by opposing end them. To die—to sleep,\n",
    "No more; and by a sleep to say we end\n",
    "The heart-ache and the thousand natural shocks\n",
    "That flesh is heir to: 'tis a consummation\n",
    "Devoutly to be wish'd. To die, to sleep;\n",
    "To sleep, perchance to dream—ay, there's the rub:\n",
    "For in that sleep of death what dreams may come,\n",
    "When we have shuffled off this mortal coil,\n",
    "Must give us pause—there's the respect\n",
    "That makes calamity of so long life.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Create vocabulary (character-level)\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Characters: {chars}\")\n",
    "\n",
    "# Encode text\n",
    "encoded = torch.tensor([char_to_idx[ch] for ch in text])\n",
    "print(f\"Text length: {len(encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474a04e",
   "metadata": {},
   "source": [
    "## 3. Create Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf43f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([16, 32])\n",
      "Output Shape: torch.Size([16, 32])\n",
      "x1, y1: tensor([[ 1, 14, 29,  1, 19, 24, 20,  3,  1, 34, 29,  1, 33, 26, 20, 20, 30,  7,\n",
      "          0, 14, 29,  1, 33, 26, 20, 20, 30,  3,  1, 30, 20, 32],\n",
      "        [23, 29, 35, 33, 16, 28, 19,  1, 28, 16, 34, 35, 32, 16, 26,  1, 33, 23,\n",
      "         29, 18, 25, 33,  0, 14, 23, 16, 34,  1, 21, 26, 20, 33],\n",
      "        [ 1, 30, 20, 32, 18, 23, 16, 28, 18, 20,  1, 34, 29,  1, 19, 32, 20, 16,\n",
      "         27, 39, 16, 38,  3,  1, 34, 23, 20, 32, 20,  2, 33,  1],\n",
      "        [ 1, 28, 29, 17, 26, 20, 32,  1, 24, 28,  1, 34, 23, 20,  1, 27, 24, 28,\n",
      "         19,  1, 34, 29,  1, 33, 35, 21, 21, 20, 32,  0, 14, 23],\n",
      "        [22,  1, 20, 28, 19,  1, 34, 23, 20, 27,  5,  1, 14, 29,  1, 19, 24, 20,\n",
      "         39, 34, 29,  1, 33, 26, 20, 20, 30,  3,  0, 12, 29,  1],\n",
      "        [23, 20, 16, 32, 34,  4, 16, 18, 23, 20,  1, 16, 28, 19,  1, 34, 23, 20,\n",
      "          1, 34, 23, 29, 35, 33, 16, 28, 19,  1, 28, 16, 34, 35],\n",
      "        [33,  1, 30, 16, 35, 33, 20, 39, 34, 23, 20, 32, 20,  2, 33,  1, 34, 23,\n",
      "         20,  1, 32, 20, 33, 30, 20, 18, 34,  0, 14, 23, 16, 34],\n",
      "        [20, 34, 23, 20, 32,  1,  2, 34, 24, 33,  1, 28, 29, 17, 26, 20, 32,  1,\n",
      "         24, 28,  1, 34, 23, 20,  1, 27, 24, 28, 19,  1, 34, 29],\n",
      "        [33, 26, 20, 20, 30,  3,  1, 30, 20, 32, 18, 23, 16, 28, 18, 20,  1, 34,\n",
      "         29,  1, 19, 32, 20, 16, 27, 39, 16, 38,  3,  1, 34, 23],\n",
      "        [32, 20, 16, 27, 33,  1, 27, 16, 38,  1, 18, 29, 27, 20,  3,  0, 15, 23,\n",
      "         20, 28,  1, 37, 20,  1, 23, 16, 36, 20,  1, 33, 23, 35],\n",
      "        [29, 18, 25, 33,  0, 14, 23, 16, 34,  1, 21, 26, 20, 33, 23,  1, 24, 33,\n",
      "          1, 23, 20, 24, 32,  1, 34, 29,  6,  1,  2, 34, 24, 33],\n",
      "        [19,  5,  1, 14, 29,  1, 19, 24, 20,  3,  1, 34, 29,  1, 33, 26, 20, 20,\n",
      "         30,  7,  0, 14, 29,  1, 33, 26, 20, 20, 30,  3,  1, 30],\n",
      "        [23,  1, 37, 23, 16, 34,  1, 19, 32, 20, 16, 27, 33,  1, 27, 16, 38,  1,\n",
      "         18, 29, 27, 20,  3,  0, 15, 23, 20, 28,  1, 37, 20,  1],\n",
      "        [ 0, 14, 23, 20,  1, 23, 20, 16, 32, 34,  4, 16, 18, 23, 20,  1, 16, 28,\n",
      "         19,  1, 34, 23, 20,  1, 34, 23, 29, 35, 33, 16, 28, 19],\n",
      "        [19, 32, 20, 16, 27, 39, 16, 38,  3,  1, 34, 23, 20, 32, 20,  2, 33,  1,\n",
      "         34, 23, 20,  1, 32, 35, 17,  6,  0, 10, 29, 32,  1, 24],\n",
      "        [21,  1, 34, 23, 24, 33,  1, 27, 29, 32, 34, 16, 26,  1, 18, 29, 24, 26,\n",
      "          3,  0, 11, 35, 33, 34,  1, 22, 24, 36, 20,  1, 35, 33]])\n",
      "tensor([[14, 29,  1, 19, 24, 20,  3,  1, 34, 29,  1, 33, 26, 20, 20, 30,  7,  0,\n",
      "         14, 29,  1, 33, 26, 20, 20, 30,  3,  1, 30, 20, 32, 18],\n",
      "        [29, 35, 33, 16, 28, 19,  1, 28, 16, 34, 35, 32, 16, 26,  1, 33, 23, 29,\n",
      "         18, 25, 33,  0, 14, 23, 16, 34,  1, 21, 26, 20, 33, 23],\n",
      "        [30, 20, 32, 18, 23, 16, 28, 18, 20,  1, 34, 29,  1, 19, 32, 20, 16, 27,\n",
      "         39, 16, 38,  3,  1, 34, 23, 20, 32, 20,  2, 33,  1, 34],\n",
      "        [28, 29, 17, 26, 20, 32,  1, 24, 28,  1, 34, 23, 20,  1, 27, 24, 28, 19,\n",
      "          1, 34, 29,  1, 33, 35, 21, 21, 20, 32,  0, 14, 23, 20],\n",
      "        [ 1, 20, 28, 19,  1, 34, 23, 20, 27,  5,  1, 14, 29,  1, 19, 24, 20, 39,\n",
      "         34, 29,  1, 33, 26, 20, 20, 30,  3,  0, 12, 29,  1, 27],\n",
      "        [20, 16, 32, 34,  4, 16, 18, 23, 20,  1, 16, 28, 19,  1, 34, 23, 20,  1,\n",
      "         34, 23, 29, 35, 33, 16, 28, 19,  1, 28, 16, 34, 35, 32],\n",
      "        [ 1, 30, 16, 35, 33, 20, 39, 34, 23, 20, 32, 20,  2, 33,  1, 34, 23, 20,\n",
      "          1, 32, 20, 33, 30, 20, 18, 34,  0, 14, 23, 16, 34,  1],\n",
      "        [34, 23, 20, 32,  1,  2, 34, 24, 33,  1, 28, 29, 17, 26, 20, 32,  1, 24,\n",
      "         28,  1, 34, 23, 20,  1, 27, 24, 28, 19,  1, 34, 29,  1],\n",
      "        [26, 20, 20, 30,  3,  1, 30, 20, 32, 18, 23, 16, 28, 18, 20,  1, 34, 29,\n",
      "          1, 19, 32, 20, 16, 27, 39, 16, 38,  3,  1, 34, 23, 20],\n",
      "        [20, 16, 27, 33,  1, 27, 16, 38,  1, 18, 29, 27, 20,  3,  0, 15, 23, 20,\n",
      "         28,  1, 37, 20,  1, 23, 16, 36, 20,  1, 33, 23, 35, 21],\n",
      "        [18, 25, 33,  0, 14, 23, 16, 34,  1, 21, 26, 20, 33, 23,  1, 24, 33,  1,\n",
      "         23, 20, 24, 32,  1, 34, 29,  6,  1,  2, 34, 24, 33,  1],\n",
      "        [ 5,  1, 14, 29,  1, 19, 24, 20,  3,  1, 34, 29,  1, 33, 26, 20, 20, 30,\n",
      "          7,  0, 14, 29,  1, 33, 26, 20, 20, 30,  3,  1, 30, 20],\n",
      "        [ 1, 37, 23, 16, 34,  1, 19, 32, 20, 16, 27, 33,  1, 27, 16, 38,  1, 18,\n",
      "         29, 27, 20,  3,  0, 15, 23, 20, 28,  1, 37, 20,  1, 23],\n",
      "        [14, 23, 20,  1, 23, 20, 16, 32, 34,  4, 16, 18, 23, 20,  1, 16, 28, 19,\n",
      "          1, 34, 23, 20,  1, 34, 23, 29, 35, 33, 16, 28, 19,  1],\n",
      "        [32, 20, 16, 27, 39, 16, 38,  3,  1, 34, 23, 20, 32, 20,  2, 33,  1, 34,\n",
      "         23, 20,  1, 32, 35, 17,  6,  0, 10, 29, 32,  1, 24, 28],\n",
      "        [ 1, 34, 23, 24, 33,  1, 27, 29, 32, 34, 16, 26,  1, 18, 29, 24, 26,  3,\n",
      "          0, 11, 35, 33, 34,  1, 22, 24, 36, 20,  1, 35, 33,  1]])\n",
      "x2, y2: tensor([[34, 23, 16, 34,  1, 24, 33,  1, 34, 23, 20,  1, 31, 35, 20, 33, 34, 24,\n",
      "         29, 28,  6,  0, 15, 23, 20, 34, 23, 20, 32,  1,  2, 34],\n",
      "        [ 1, 37, 24, 33, 23,  2, 19,  5,  1, 14, 29,  1, 19, 24, 20,  3,  1, 34,\n",
      "         29,  1, 33, 26, 20, 20, 30,  7,  0, 14, 29,  1, 33, 26],\n",
      "        [29,  6,  1,  2, 34, 24, 33,  1, 16,  1, 18, 29, 28, 33, 35, 27, 27, 16,\n",
      "         34, 24, 29, 28,  0,  9, 20, 36, 29, 35, 34, 26, 38,  1],\n",
      "        [35, 34, 32, 16, 22, 20, 29, 35, 33,  1, 21, 29, 32, 34, 35, 28, 20,  3,\n",
      "          0, 13, 32,  1, 34, 29,  1, 34, 16, 25, 20,  1, 16, 32],\n",
      "        [33, 26, 20, 20, 30,  3,  0, 12, 29,  1, 27, 29, 32, 20,  7,  1, 16, 28,\n",
      "         19,  1, 17, 38,  1, 16,  1, 33, 26, 20, 20, 30,  1, 34],\n",
      "        [29,  1, 19, 24, 20,  3,  1, 34, 29,  1, 33, 26, 20, 20, 30,  7,  0, 14,\n",
      "         29,  1, 33, 26, 20, 20, 30,  3,  1, 30, 20, 32, 18, 23],\n",
      "        [ 1, 34, 29,  6,  1,  2, 34, 24, 33,  1, 16,  1, 18, 29, 28, 33, 35, 27,\n",
      "         27, 16, 34, 24, 29, 28,  0,  9, 20, 36, 29, 35, 34, 26],\n",
      "        [28, 22,  1, 20, 28, 19,  1, 34, 23, 20, 27,  5,  1, 14, 29,  1, 19, 24,\n",
      "         20, 39, 34, 29,  1, 33, 26, 20, 20, 30,  3,  0, 12, 29],\n",
      "        [16, 38,  1, 37, 20,  1, 20, 28, 19,  0, 14, 23, 20,  1, 23, 20, 16, 32,\n",
      "         34,  4, 16, 18, 23, 20,  1, 16, 28, 19,  1, 34, 23, 20],\n",
      "        [21,  1, 34, 32, 29, 35, 17, 26, 20, 33,  0,  8, 28, 19,  1, 17, 38,  1,\n",
      "         29, 30, 30, 29, 33, 24, 28, 22,  1, 20, 28, 19,  1, 34],\n",
      "        [20, 32, 18, 23, 16, 28, 18, 20,  1, 34, 29,  1, 19, 32, 20, 16, 27, 39,\n",
      "         16, 38,  3,  1, 34, 23, 20, 32, 20,  2, 33,  1, 34, 23],\n",
      "        [21, 29, 32, 34, 35, 28, 20,  3,  0, 13, 32,  1, 34, 29,  1, 34, 16, 25,\n",
      "         20,  1, 16, 32, 27, 33,  1, 16, 22, 16, 24, 28, 33, 34],\n",
      "        [23, 20, 28,  1, 37, 20,  1, 23, 16, 36, 20,  1, 33, 23, 35, 21, 21, 26,\n",
      "         20, 19,  1, 29, 21, 21,  1, 34, 23, 24, 33,  1, 27, 29],\n",
      "        [20,  2, 33,  1, 34, 23, 20,  1, 32, 20, 33, 30, 20, 18, 34,  0, 14, 23,\n",
      "         16, 34,  1, 27, 16, 25, 20, 33,  1, 18, 16, 26, 16, 27],\n",
      "        [20, 30,  1, 29, 21,  1, 19, 20, 16, 34, 23,  1, 37, 23, 16, 34,  1, 19,\n",
      "         32, 20, 16, 27, 33,  1, 27, 16, 38,  1, 18, 29, 27, 20],\n",
      "        [14, 29,  1, 19, 24, 20, 39, 34, 29,  1, 33, 26, 20, 20, 30,  3,  0, 12,\n",
      "         29,  1, 27, 29, 32, 20,  7,  1, 16, 28, 19,  1, 17, 38]])\n",
      "tensor([[23, 16, 34,  1, 24, 33,  1, 34, 23, 20,  1, 31, 35, 20, 33, 34, 24, 29,\n",
      "         28,  6,  0, 15, 23, 20, 34, 23, 20, 32,  1,  2, 34, 24],\n",
      "        [37, 24, 33, 23,  2, 19,  5,  1, 14, 29,  1, 19, 24, 20,  3,  1, 34, 29,\n",
      "          1, 33, 26, 20, 20, 30,  7,  0, 14, 29,  1, 33, 26, 20],\n",
      "        [ 6,  1,  2, 34, 24, 33,  1, 16,  1, 18, 29, 28, 33, 35, 27, 27, 16, 34,\n",
      "         24, 29, 28,  0,  9, 20, 36, 29, 35, 34, 26, 38,  1, 34],\n",
      "        [34, 32, 16, 22, 20, 29, 35, 33,  1, 21, 29, 32, 34, 35, 28, 20,  3,  0,\n",
      "         13, 32,  1, 34, 29,  1, 34, 16, 25, 20,  1, 16, 32, 27],\n",
      "        [26, 20, 20, 30,  3,  0, 12, 29,  1, 27, 29, 32, 20,  7,  1, 16, 28, 19,\n",
      "          1, 17, 38,  1, 16,  1, 33, 26, 20, 20, 30,  1, 34, 29],\n",
      "        [ 1, 19, 24, 20,  3,  1, 34, 29,  1, 33, 26, 20, 20, 30,  7,  0, 14, 29,\n",
      "          1, 33, 26, 20, 20, 30,  3,  1, 30, 20, 32, 18, 23, 16],\n",
      "        [34, 29,  6,  1,  2, 34, 24, 33,  1, 16,  1, 18, 29, 28, 33, 35, 27, 27,\n",
      "         16, 34, 24, 29, 28,  0,  9, 20, 36, 29, 35, 34, 26, 38],\n",
      "        [22,  1, 20, 28, 19,  1, 34, 23, 20, 27,  5,  1, 14, 29,  1, 19, 24, 20,\n",
      "         39, 34, 29,  1, 33, 26, 20, 20, 30,  3,  0, 12, 29,  1],\n",
      "        [38,  1, 37, 20,  1, 20, 28, 19,  0, 14, 23, 20,  1, 23, 20, 16, 32, 34,\n",
      "          4, 16, 18, 23, 20,  1, 16, 28, 19,  1, 34, 23, 20,  1],\n",
      "        [ 1, 34, 32, 29, 35, 17, 26, 20, 33,  0,  8, 28, 19,  1, 17, 38,  1, 29,\n",
      "         30, 30, 29, 33, 24, 28, 22,  1, 20, 28, 19,  1, 34, 23],\n",
      "        [32, 18, 23, 16, 28, 18, 20,  1, 34, 29,  1, 19, 32, 20, 16, 27, 39, 16,\n",
      "         38,  3,  1, 34, 23, 20, 32, 20,  2, 33,  1, 34, 23, 20],\n",
      "        [29, 32, 34, 35, 28, 20,  3,  0, 13, 32,  1, 34, 29,  1, 34, 16, 25, 20,\n",
      "          1, 16, 32, 27, 33,  1, 16, 22, 16, 24, 28, 33, 34,  1],\n",
      "        [20, 28,  1, 37, 20,  1, 23, 16, 36, 20,  1, 33, 23, 35, 21, 21, 26, 20,\n",
      "         19,  1, 29, 21, 21,  1, 34, 23, 24, 33,  1, 27, 29, 32],\n",
      "        [ 2, 33,  1, 34, 23, 20,  1, 32, 20, 33, 30, 20, 18, 34,  0, 14, 23, 16,\n",
      "         34,  1, 27, 16, 25, 20, 33,  1, 18, 16, 26, 16, 27, 24],\n",
      "        [30,  1, 29, 21,  1, 19, 20, 16, 34, 23,  1, 37, 23, 16, 34,  1, 19, 32,\n",
      "         20, 16, 27, 33,  1, 27, 16, 38,  1, 18, 29, 27, 20,  3],\n",
      "        [29,  1, 19, 24, 20, 39, 34, 29,  1, 33, 26, 20, 20, 30,  3,  0, 12, 29,\n",
      "          1, 27, 29, 32, 20,  7,  1, 16, 28, 19,  1, 17, 38,  1]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Any\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, encoded_text, seq_len) -> None:\n",
    "        super().__init__()\n",
    "        self.data = encoded_text\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "    \n",
    "    def __getitem__(self, idx) -> Any:\n",
    "        # Input: seq_len tokens\n",
    "        # Output: next seq_len tokens (shifted by 1)\n",
    "        \n",
    "        x = self.data[idx : idx + self.seq_len]\n",
    "        y = self.data[idx + 1: idx + self.seq_len + 1]\n",
    "        return x, y\n",
    "\n",
    "# Create dataset\n",
    "seq_len = 32\n",
    "batch_size = 16\n",
    "dataset = CharDataset(encoded_text=encoded, seq_len=seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Check one batch\n",
    "x, y = next(iter(dataloader))\n",
    "x2, y2 = next(iter(dataloader))\n",
    "print(f\"Input Shape: {x.shape}\")\n",
    "print(f\"Output Shape: {y.shape}\")\n",
    "print(f\"x1, y1: {x}\\n{y}\")\n",
    "print(f\"x2, y2: {x2}\\n{y2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed02d41",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a1ce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.8121\n",
      "Epoch 2/50, Loss: 2.1679\n",
      "Epoch 3/50, Loss: 1.9153\n",
      "Epoch 4/50, Loss: 1.7190\n",
      "Epoch 5/50, Loss: 1.5180\n",
      "Epoch 6/50, Loss: 1.3436\n",
      "Epoch 7/50, Loss: 1.2062\n",
      "Epoch 8/50, Loss: 1.1128\n",
      "Epoch 9/50, Loss: 1.0397\n",
      "Epoch 10/50, Loss: 0.9917\n",
      "Epoch 11/50, Loss: 0.9542\n",
      "Epoch 12/50, Loss: 0.9399\n",
      "Epoch 13/50, Loss: 0.9156\n",
      "Epoch 14/50, Loss: 0.9026\n",
      "Epoch 15/50, Loss: 0.8865\n",
      "Epoch 16/50, Loss: 0.8782\n",
      "Epoch 17/50, Loss: 0.8677\n",
      "Epoch 18/50, Loss: 0.8599\n",
      "Epoch 19/50, Loss: 0.8567\n",
      "Epoch 20/50, Loss: 0.8459\n",
      "Epoch 21/50, Loss: 0.8429\n",
      "Epoch 22/50, Loss: 0.8430\n",
      "Epoch 23/50, Loss: 0.8347\n",
      "Epoch 24/50, Loss: 0.8278\n",
      "Epoch 25/50, Loss: 0.8262\n",
      "Epoch 26/50, Loss: 0.8198\n",
      "Epoch 27/50, Loss: 0.8202\n",
      "Epoch 28/50, Loss: 0.8165\n",
      "Epoch 29/50, Loss: 0.8152\n",
      "Epoch 30/50, Loss: 0.8109\n",
      "Epoch 31/50, Loss: 0.8106\n",
      "Epoch 32/50, Loss: 0.8061\n",
      "Epoch 33/50, Loss: 0.8049\n",
      "Epoch 34/50, Loss: 0.8013\n",
      "Epoch 35/50, Loss: 0.8040\n",
      "Epoch 36/50, Loss: 0.7952\n",
      "Epoch 37/50, Loss: 0.7977\n",
      "Epoch 38/50, Loss: 0.7948\n",
      "Epoch 39/50, Loss: 0.7926\n",
      "Epoch 40/50, Loss: 0.7857\n",
      "Epoch 41/50, Loss: 0.7783\n",
      "Epoch 42/50, Loss: 0.7626\n",
      "Epoch 43/50, Loss: 0.7166\n",
      "Epoch 44/50, Loss: 0.6505\n",
      "Epoch 45/50, Loss: 0.5834\n",
      "Epoch 46/50, Loss: 0.5175\n",
      "Epoch 47/50, Loss: 0.4711\n",
      "Epoch 48/50, Loss: 0.4253\n",
      "Epoch 49/50, Loss: 0.3924\n",
      "Epoch 50/50, Loss: 0.3557\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "vocab_size = len(chars)\n",
    "d_model = 128\n",
    "n_heads = 4\n",
    "d_ff = 512\n",
    "n_layers = 4\n",
    "max_seq_len = 128\n",
    "learning_rate = 3e-4\n",
    "n_epochs = 50\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LanguageModel(vocab_size=vocab_size, d_model=d_model, n_heads=n_heads, d_ff=d_ff, n_layers=n_layers, max_seq_len=max_seq_len)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(x) # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "        # Reshape for cross-entropy\n",
    "        # CrossEntropyLoss expects: (batch * seq_len, vocab_size) and (batch_size * seq_len)\n",
    "        # logits = logits.view(batch_size * seq_len, vocab_size)\n",
    "        logits = logits.view(-1, vocab_size)\n",
    "        y = y.view(-1)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b7e2d",
   "metadata": {},
   "source": [
    "## 5. Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "573e9506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated text:\n",
      "love mevortomorrtortormortorrmormrmormorrmormrrmoatormormormormirmioatarmormormormormoamormoimormmoutarmorm\n"
     ]
    }
   ],
   "source": [
    "def generate(model, start_text, max_new_tokens=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode starting text\n",
    "    context = [char_to_idx[ch] for ch in start_text]\n",
    "    context = torch.tensor(context, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    generated = list(start_text)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get predictions\n",
    "            logits = model(context) # (1, seq_len, vocab_size)\n",
    "\n",
    "            # Get logits for last position\n",
    "            logits = logits[0, -1, :] / temperature # (vocab_size)\n",
    "\n",
    "            # Sample from distribution\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "            \n",
    "            # Append to context\n",
    "            context = torch.cat([context, torch.tensor([[next_idx]], device=device)], dim=1)\n",
    "\n",
    "            # Add to generated text\n",
    "            generated.append(chars[next_idx])\n",
    "    \n",
    "    return ''.join(generated)\n",
    "\n",
    "# Generate\n",
    "start = \"love me\"\n",
    "generated_text = generate(model, start, max_new_tokens=100, temperature=0.8)\n",
    "print(\"\\nGenerated text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f3fb09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be To be To be To be so be so be s\n",
      "To beso bes\n",
      "To bes\n",
      "To beTo bes\n",
      "To beso beseTo bes\n",
      "To beso beseTo be\n",
      "To beuto theto theto thetoistheto thetois thon the o theto theton theto theto theton the, s tho n\n",
      "Whe, th\n"
     ]
    }
   ],
   "source": [
    "def generate(model, start_text, max_new_tokens=100, temperature=1.0, top_k=None):\n",
    "    model.eval()\n",
    "    \n",
    "    context = [char_to_idx[ch] for ch in start_text]\n",
    "    context = torch.tensor(context, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    generated = list(start_text)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Limit context to max_seq_len\n",
    "            context_input = context if context.size(1) <= max_seq_len else context[:, -max_seq_len:]\n",
    "            \n",
    "            logits = model(context_input)[0, -1, :] / temperature\n",
    "            \n",
    "            # Top-k sampling (prevents low-probability garbage)\n",
    "            if top_k is not None:\n",
    "                top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
    "                logits = torch.full_like(logits, float('-inf'))\n",
    "                logits[top_k_indices] = top_k_logits\n",
    "            \n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "            \n",
    "            context = torch.cat([context, torch.tensor([[next_idx]], device=device)], dim=1)\n",
    "            generated.append(chars[next_idx])\n",
    "    \n",
    "    return ''.join(generated)\n",
    "\n",
    "# Try different settings\n",
    "print(generate(model, \"To be\", max_new_tokens=100, temperature=0.8, top_k=5))\n",
    "print(generate(model, \"To be\", max_new_tokens=100, temperature=1.2, top_k=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4mip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
